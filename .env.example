# ========================================
# LLM PROVIDER CONFIGURATION
# ========================================
# Escolha qual provedor de LLM usar: "openai" ou "google"
LLM_PROVIDER=openai

# ========================================
# OPENAI CONFIGURATION
# ========================================
# Use estas configurações se LLM_PROVIDER=openai
# Obtenha sua chave em: https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-sua_chave_openai_aqui
OPENAI_EMBEDDING_MODEL=text-embedding-3-small
OPENAI_CHAT_MODEL=gpt-4o-mini

# ========================================
# GOOGLE GEMINI CONFIGURATION
# ========================================
# Use estas configurações se LLM_PROVIDER=google
# Obtenha sua chave em: https://aistudio.google.com/app/apikey
GOOGLE_API_KEY=AIza_sua_chave_google_aqui
GOOGLE_EMBEDDING_MODEL=models/embedding-001
GOOGLE_CHAT_MODEL=gemini-2.0-flash-exp

# ========================================
# DATABASE CONFIGURATION
# ========================================
# String de conexão completa com PostgreSQL
DATABASE_URL=postgresql://postgres:postgres@localhost:5432/rag

# Configurações individuais (usadas pelo docker-compose)
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_DB=rag
POSTGRES_USER=postgres
POSTGRES_PASSWORD=postgres

# Nome da collection/tabela de vetores
PG_VECTOR_COLLECTION_NAME=pdf_documents

# ========================================
# DOCUMENT PROCESSING CONFIGURATION
# ========================================
# Tamanho dos chunks de texto (em caracteres)
CHUNK_SIZE=1000

# Sobreposição entre chunks (em caracteres)
CHUNK_OVERLAP=150

# Número de documentos similares a retornar na busca
SEARCH_K=10

# Caminho padrão para o PDF (pode ser sobrescrito via argumento CLI)
PDF_PATH=document.pdf

# ========================================
# APPLICATION CONFIGURATION
# ========================================
# Nível de log: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=ERROR